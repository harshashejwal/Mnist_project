{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ypra1gC1bszQ",
        "outputId": "ab7e4133-d6c0-4c52-be47-fe212c2c2e57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1313/1313 [==============================] - 147s 108ms/step - loss: 0.3281 - accuracy: 0.8955 - val_loss: 0.1212 - val_accuracy: 0.9634\n",
            "313/313 [==============================] - 18s 56ms/step\n",
            "313/313 [==============================] - 10s 32ms/step - loss: 0.1117 - accuracy: 0.9676\n",
            "test loss on 10000 test samples 0.1116962805390358\n",
            "validation Accuracy on 10000 test samples 0.9675999879837036\n",
            "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
            "...layers\\activation\n",
            "......vars\n",
            "...layers\\activation_1\n",
            "......vars\n",
            "...layers\\activation_2\n",
            "......vars\n",
            "...layers\\activation_3\n",
            "......vars\n",
            "...layers\\activation_4\n",
            "......vars\n",
            "...layers\\activation_5\n",
            "......vars\n",
            "...layers\\conv2d\n",
            "......vars\n",
            ".........0\n",
            ".........1\n",
            "...layers\\conv2d_1\n",
            "......vars\n",
            ".........0\n",
            ".........1\n",
            "...layers\\conv2d_2\n",
            "......vars\n",
            ".........0\n",
            ".........1\n",
            "...layers\\dense\n",
            "......vars\n",
            ".........0\n",
            ".........1\n",
            "...layers\\dense_1\n",
            "......vars\n",
            ".........0\n",
            ".........1\n",
            "...layers\\dense_2\n",
            "......vars\n",
            ".........0\n",
            ".........1\n",
            "...layers\\flatten\n",
            "......vars\n",
            "...layers\\max_pooling2d\n",
            "......vars\n",
            "...layers\\max_pooling2d_1\n",
            "......vars\n",
            "...layers\\max_pooling2d_2\n",
            "......vars\n",
            "...metrics\\mean\n",
            "......vars\n",
            ".........0\n",
            ".........1\n",
            "...metrics\\mean_metric_wrapper\n",
            "......vars\n",
            ".........0\n",
            ".........1\n",
            "...optimizer\n",
            "......vars\n",
            ".........0\n",
            ".........1\n",
            ".........10\n",
            ".........11\n",
            ".........12\n",
            ".........13\n",
            ".........14\n",
            ".........15\n",
            ".........16\n",
            ".........17\n",
            ".........18\n",
            ".........19\n",
            ".........2\n",
            ".........20\n",
            ".........21\n",
            ".........22\n",
            ".........23\n",
            ".........24\n",
            ".........3\n",
            ".........4\n",
            ".........5\n",
            ".........6\n",
            ".........7\n",
            ".........8\n",
            ".........9\n",
            "...vars\n",
            "Keras model archive saving:\n",
            "File Name                                             Modified             Size\n",
            "config.json                                    2022-12-31 05:15:23         5042\n",
            "metadata.json                                  2022-12-31 05:15:23           64\n",
            "variables.h5                                   2022-12-31 05:15:24      1027072\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout,Activation,Flatten,Conv2D,MaxPooling2D\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train),(x_test,y_test) = mnist.load_data()\n",
        "x_train=tf.keras.utils.normalize(x_train,axis=1)\n",
        "x_test=tf.keras.utils.normalize(x_test,axis=1)\n",
        "\n",
        "\n",
        "x_trainr=np.array(x_train).reshape(-1,28,28,1)\n",
        "x_testr=np.array(x_test).reshape(-1,28,28,1)\n",
        "\n",
        "\n",
        "model=Sequential()\n",
        "\n",
        "#1st convolustion layer\n",
        "model.add(Conv2D(64,(3,3),input_shape=x_trainr.shape[1:]))#only for 1st convotution layer requred to mesion input layer size#64 FILTER ARE APPLIED TO INPUT\n",
        "model.add(Activation(\"relu\"))#TO MAKE A NON LINEAR\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))#ONLY IT TAKE SINGLE 2*2 MATRIX OTHER WILL REMOVE\n",
        "\n",
        "#2nd convolustion layer\n",
        "model.add(Conv2D(64,(3,3)))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "#3rd convolustion layer\n",
        "model.add(Conv2D(64,(3,3)))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "#Fully connected layer1\n",
        "model.add (Flatten()) #before fully connected need to flatten 2D to 1D\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "#Fully connected layer2\n",
        "model.add(Dense(32))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "#last fully layerd\n",
        "model.add(Dense(10))#must be 10\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_trainr,y_train,epochs=1,validation_split=0.3)\n",
        "\n",
        "predictions=model.predict([x_testr])\n",
        "\n",
        "test_loss,test_acc= model.evaluate(x_testr,y_test)\n",
        "print(\"test loss on 10000 test samples\",test_loss)\n",
        "print(\"validation Accuracy on 10000 test samples\",test_acc)\n",
        "\n",
        "import pickle\n",
        "pickle_out=open('model5.pkl','wb')\n",
        "pickle.dump(model,pickle_out)\n",
        "pickle_out.close()\n",
        "          \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "TDFu4QvWhPvY",
        "outputId": "63807c16-ab1c-4c3c-c087-1ff7039ace8f"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mCanceled future for execute_request message before replies were done"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "i=int(input(\"Enter the index number you want to print between the images Mnist test dataset from  1 to 10000 \"))\n",
        "print(np.argmax(predictions[i]))\n",
        "plt.imshow(x_test[i],cmap= plt.cm.binary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NuPWGjcJq4C",
        "outputId": "4b001928-77c4-45d7-87a0-a8d46f0ac7a2"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n\u001b[0;32m      2\u001b[0m pickle_out\u001b[39m=\u001b[39m\u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mmodel2.pkl\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m pickle\u001b[39m.\u001b[39mdump(model,pickle_out)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "pickle_out=open(\"model2.pkl\",\"wb\")\n",
        "pickle.dump(model,pickle_out)\n",
        "#pickle_out.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxW9zRZJblou"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "ec4659a12f542298a01dd6e54503a7eaf4b7eb4afbe6da4ba241b8ab6afca83f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
